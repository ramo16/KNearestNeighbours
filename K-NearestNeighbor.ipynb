{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
      "0    842302         M        17.99         10.38          122.80     1001.0   \n",
      "1    842517         M        20.57         17.77          132.90     1326.0   \n",
      "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
      "3  84348301         M        11.42         20.38           77.58      386.1   \n",
      "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
      "\n",
      "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
      "0          0.11840           0.27760          0.3001              0.14710   \n",
      "1          0.08474           0.07864          0.0869              0.07017   \n",
      "2          0.10960           0.15990          0.1974              0.12790   \n",
      "3          0.14250           0.28390          0.2414              0.10520   \n",
      "4          0.10030           0.13280          0.1980              0.10430   \n",
      "\n",
      "   ...  radius_worst  texture_worst  perimeter_worst  area_worst  \\\n",
      "0  ...         25.38          17.33           184.60      2019.0   \n",
      "1  ...         24.99          23.41           158.80      1956.0   \n",
      "2  ...         23.57          25.53           152.50      1709.0   \n",
      "3  ...         14.91          26.50            98.87       567.7   \n",
      "4  ...         22.54          16.67           152.20      1575.0   \n",
      "\n",
      "   smoothness_worst  compactness_worst  concavity_worst  concave points_worst  \\\n",
      "0            0.1622             0.6656           0.7119                0.2654   \n",
      "1            0.1238             0.1866           0.2416                0.1860   \n",
      "2            0.1444             0.4245           0.4504                0.2430   \n",
      "3            0.2098             0.8663           0.6869                0.2575   \n",
      "4            0.1374             0.2050           0.4000                0.1625   \n",
      "\n",
      "   symmetry_worst  fractal_dimension_worst  \n",
      "0          0.4601                  0.11890  \n",
      "1          0.2750                  0.08902  \n",
      "2          0.3613                  0.08758  \n",
      "3          0.6638                  0.17300  \n",
      "4          0.2364                  0.07678  \n",
      "\n",
      "[5 rows x 32 columns]\n",
      "(569, 32)\n",
      "                 id  radius_mean  texture_mean  perimeter_mean    area_mean  \\\n",
      "count  5.690000e+02   569.000000    569.000000      569.000000   569.000000   \n",
      "mean   3.037183e+07    14.127292     19.289649       91.969033   654.889104   \n",
      "std    1.250206e+08     3.524049      4.301036       24.298981   351.914129   \n",
      "min    8.670000e+03     6.981000      9.710000       43.790000   143.500000   \n",
      "25%    8.692180e+05    11.700000     16.170000       75.170000   420.300000   \n",
      "50%    9.060240e+05    13.370000     18.840000       86.240000   551.100000   \n",
      "75%    8.813129e+06    15.780000     21.800000      104.100000   782.700000   \n",
      "max    9.113205e+08    28.110000     39.280000      188.500000  2501.000000   \n",
      "\n",
      "       smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
      "count       569.000000        569.000000      569.000000           569.000000   \n",
      "mean          0.096360          0.104341        0.088799             0.048919   \n",
      "std           0.014064          0.052813        0.079720             0.038803   \n",
      "min           0.052630          0.019380        0.000000             0.000000   \n",
      "25%           0.086370          0.064920        0.029560             0.020310   \n",
      "50%           0.095870          0.092630        0.061540             0.033500   \n",
      "75%           0.105300          0.130400        0.130700             0.074000   \n",
      "max           0.163400          0.345400        0.426800             0.201200   \n",
      "\n",
      "       symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
      "count     569.000000  ...    569.000000     569.000000       569.000000   \n",
      "mean        0.181162  ...     16.269190      25.677223       107.261213   \n",
      "std         0.027414  ...      4.833242       6.146258        33.602542   \n",
      "min         0.106000  ...      7.930000      12.020000        50.410000   \n",
      "25%         0.161900  ...     13.010000      21.080000        84.110000   \n",
      "50%         0.179200  ...     14.970000      25.410000        97.660000   \n",
      "75%         0.195700  ...     18.790000      29.720000       125.400000   \n",
      "max         0.304000  ...     36.040000      49.540000       251.200000   \n",
      "\n",
      "        area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
      "count   569.000000        569.000000         569.000000       569.000000   \n",
      "mean    880.583128          0.132369           0.254265         0.272188   \n",
      "std     569.356993          0.022832           0.157336         0.208624   \n",
      "min     185.200000          0.071170           0.027290         0.000000   \n",
      "25%     515.300000          0.116600           0.147200         0.114500   \n",
      "50%     686.500000          0.131300           0.211900         0.226700   \n",
      "75%    1084.000000          0.146000           0.339100         0.382900   \n",
      "max    4254.000000          0.222600           1.058000         1.252000   \n",
      "\n",
      "       concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
      "count            569.000000      569.000000               569.000000  \n",
      "mean               0.114606        0.290076                 0.083946  \n",
      "std                0.065732        0.061867                 0.018061  \n",
      "min                0.000000        0.156500                 0.055040  \n",
      "25%                0.064930        0.250400                 0.071460  \n",
      "50%                0.099930        0.282200                 0.080040  \n",
      "75%                0.161400        0.317900                 0.092080  \n",
      "max                0.291000        0.663800                 0.207500  \n",
      "\n",
      "[8 rows x 31 columns]\n",
      "KNN 0.9252657004830919 0.03130572699293886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vamsi\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\vamsi\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\vamsi\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\vamsi\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\vamsi\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\vamsi\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\vamsi\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\vamsi\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\vamsi\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\vamsi\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic 0.9516908212560387 0.03490852142755838\n",
      "['2' '2' '2' '4' '2' '2' '2' '2' '2' '2' '4' '2' '2' '2' '4' '4' '2' '4'\n",
      " '4' '4' '4' '2' '2' '2' '4' '2' '2' '2' '2' '4' '2' '4' '2' '4' '2' '4'\n",
      " '2' '4' '2' '4' '4' '2' '4' '2' '4' '4' '2' '2' '2' '4' '4' '2' '4' '2'\n",
      " '2' '2' '2' '2' '2' '4' '4' '4' '2' '2' '4' '2' '4' '4' '4' '2' '2' '4'\n",
      " '2' '2' '4' '2' '2' '2' '2' '2' '4' '4' '4' '2' '4' '2' '2' '2' '4' '4'\n",
      " '2' '4' '2' '4' '2' '2' '4' '2' '2' '2' '2' '2' '2' '2' '4' '2' '4' '2'\n",
      " '4' '2' '2' '4' '4' '2']\n",
      "Accuracy is  91.22807017543859 % for K-Value: 1\n",
      "0.9122807017543859\n",
      "['2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '4' '2' '4'\n",
      " '4' '4' '4' '2' '2' '2' '4' '2' '2' '2' '2' '4' '2' '4' '2' '4' '2' '4'\n",
      " '2' '4' '2' '4' '4' '2' '4' '2' '4' '4' '2' '2' '2' '4' '4' '2' '4' '2'\n",
      " '2' '2' '2' '2' '2' '4' '4' '4' '2' '2' '4' '2' '4' '4' '4' '2' '2' '4'\n",
      " '2' '2' '4' '2' '2' '2' '2' '2' '4' '4' '4' '2' '4' '2' '2' '2' '4' '4'\n",
      " '2' '4' '2' '2' '2' '2' '4' '2' '2' '2' '2' '2' '2' '2' '4' '2' '4' '2'\n",
      " '4' '2' '2' '4' '4' '2']\n",
      "Accuracy is  92.98245614035088 % for K-Value: 2\n",
      "0.9298245614035088\n",
      "['4' '2' '2' '4' '2' '2' '2' '2' '2' '2' '4' '2' '2' '4' '4' '4' '2' '4'\n",
      " '4' '4' '4' '4' '2' '2' '4' '2' '2' '2' '2' '4' '2' '4' '2' '4' '2' '4'\n",
      " '2' '4' '2' '4' '4' '2' '4' '2' '4' '4' '2' '2' '2' '4' '4' '2' '4' '2'\n",
      " '2' '2' '2' '2' '2' '4' '4' '4' '2' '2' '4' '2' '4' '4' '4' '2' '2' '4'\n",
      " '2' '2' '4' '2' '2' '2' '2' '2' '4' '4' '4' '2' '4' '2' '2' '2' '4' '4'\n",
      " '2' '4' '2' '2' '2' '2' '4' '2' '2' '2' '2' '2' '2' '2' '4' '2' '4' '4'\n",
      " '4' '4' '2' '4' '4' '2']\n",
      "Accuracy is  91.22807017543859 % for K-Value: 3\n",
      "0.9122807017543859\n",
      "['4' '2' '2' '4' '2' '2' '2' '2' '2' '2' '2' '2' '2' '4' '4' '4' '2' '4'\n",
      " '4' '4' '4' '4' '2' '2' '4' '2' '2' '2' '2' '4' '2' '4' '2' '4' '2' '4'\n",
      " '2' '4' '2' '4' '4' '2' '4' '2' '4' '4' '2' '2' '2' '4' '4' '2' '4' '2'\n",
      " '2' '2' '2' '2' '2' '4' '4' '4' '2' '2' '4' '2' '4' '4' '4' '2' '2' '4'\n",
      " '2' '2' '4' '2' '2' '2' '2' '2' '4' '4' '4' '2' '4' '2' '2' '2' '4' '4'\n",
      " '2' '4' '2' '2' '2' '2' '4' '2' '2' '2' '2' '2' '2' '2' '4' '2' '4' '2'\n",
      " '4' '4' '2' '4' '4' '2']\n",
      "Accuracy is  92.98245614035088 % for K-Value: 4\n",
      "0.9298245614035088\n",
      "['4' '2' '2' '4' '2' '2' '2' '2' '2' '2' '2' '2' '2' '4' '4' '4' '2' '4'\n",
      " '4' '4' '4' '4' '2' '2' '4' '2' '2' '2' '2' '4' '2' '4' '2' '4' '2' '4'\n",
      " '2' '4' '2' '4' '4' '2' '4' '2' '4' '4' '2' '2' '2' '4' '4' '2' '4' '2'\n",
      " '2' '2' '2' '2' '2' '4' '4' '4' '2' '2' '4' '2' '4' '4' '4' '2' '2' '4'\n",
      " '2' '2' '4' '2' '2' '2' '2' '2' '4' '4' '4' '2' '4' '2' '2' '2' '4' '4'\n",
      " '2' '4' '2' '4' '2' '2' '4' '2' '2' '2' '2' '2' '2' '2' '4' '2' '4' '2'\n",
      " '4' '4' '2' '4' '4' '2']\n",
      "Accuracy is  93.85964912280701 % for K-Value: 5\n",
      "0.9385964912280702\n",
      "['4' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '4' '2' '4' '2' '4'\n",
      " '4' '4' '4' '4' '2' '2' '4' '2' '2' '2' '2' '4' '2' '4' '2' '4' '2' '4'\n",
      " '2' '4' '2' '4' '4' '2' '4' '2' '4' '4' '2' '2' '2' '4' '4' '2' '4' '2'\n",
      " '2' '2' '2' '2' '2' '4' '4' '4' '2' '2' '4' '2' '4' '4' '4' '2' '2' '4'\n",
      " '2' '2' '4' '2' '2' '2' '2' '2' '4' '4' '4' '2' '4' '2' '2' '2' '4' '4'\n",
      " '2' '4' '2' '4' '2' '2' '4' '2' '2' '2' '2' '2' '2' '2' '4' '2' '4' '2'\n",
      " '4' '4' '2' '4' '4' '2']\n",
      "Accuracy is  95.6140350877193 % for K-Value: 6\n",
      "0.956140350877193\n",
      "['4' '2' '2' '4' '2' '2' '2' '2' '2' '2' '2' '2' '2' '4' '2' '4' '2' '4'\n",
      " '4' '4' '4' '4' '2' '2' '4' '2' '2' '2' '2' '4' '2' '4' '2' '4' '2' '4'\n",
      " '2' '4' '2' '4' '4' '2' '4' '2' '4' '4' '2' '2' '2' '4' '4' '2' '4' '2'\n",
      " '2' '2' '2' '2' '2' '4' '4' '4' '2' '2' '4' '2' '4' '4' '4' '2' '2' '4'\n",
      " '2' '2' '4' '2' '2' '2' '2' '2' '4' '4' '4' '2' '4' '2' '2' '2' '4' '4'\n",
      " '2' '4' '2' '4' '2' '2' '4' '2' '2' '2' '2' '2' '2' '2' '4' '2' '4' '2'\n",
      " '4' '4' '2' '4' '4' '2']\n",
      "Accuracy is  94.73684210526315 % for K-Value: 7\n",
      "0.9473684210526315\n",
      "['4' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '4' '2' '4' '2' '4'\n",
      " '4' '4' '4' '4' '2' '2' '4' '2' '2' '2' '2' '4' '2' '4' '2' '4' '2' '4'\n",
      " '2' '4' '2' '4' '4' '2' '4' '2' '2' '4' '2' '2' '2' '4' '4' '2' '4' '2'\n",
      " '2' '2' '2' '2' '2' '4' '4' '4' '2' '2' '4' '2' '4' '4' '4' '2' '2' '4'\n",
      " '2' '2' '4' '2' '2' '2' '2' '2' '4' '4' '4' '2' '4' '2' '2' '2' '4' '4'\n",
      " '2' '4' '2' '4' '2' '2' '4' '2' '2' '2' '2' '2' '2' '2' '4' '2' '4' '2'\n",
      " '4' '4' '2' '4' '4' '2']\n",
      "Accuracy is  96.49122807017544 % for K-Value: 8\n",
      "0.9649122807017544\n",
      "['4' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '4' '2' '4' '2' '4'\n",
      " '4' '4' '4' '4' '2' '2' '4' '2' '2' '2' '2' '4' '2' '4' '2' '4' '2' '4'\n",
      " '2' '4' '2' '4' '4' '2' '4' '2' '2' '4' '2' '2' '2' '4' '4' '2' '4' '2'\n",
      " '2' '2' '2' '2' '2' '4' '4' '4' '2' '2' '4' '2' '4' '4' '4' '2' '2' '4'\n",
      " '2' '2' '4' '2' '2' '2' '2' '2' '4' '4' '4' '2' '4' '2' '2' '2' '4' '4'\n",
      " '2' '4' '2' '4' '2' '2' '4' '2' '2' '2' '2' '2' '2' '2' '4' '2' '4' '2'\n",
      " '4' '4' '2' '4' '4' '2']\n",
      "Accuracy is  96.49122807017544 % for K-Value: 9\n",
      "0.9649122807017544\n",
      "['4' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '4' '2' '4' '2' '4'\n",
      " '4' '4' '4' '4' '2' '2' '4' '2' '2' '2' '2' '4' '2' '4' '2' '4' '2' '4'\n",
      " '2' '4' '2' '4' '4' '2' '4' '2' '2' '4' '2' '2' '2' '4' '4' '2' '4' '2'\n",
      " '2' '2' '2' '2' '2' '4' '4' '4' '2' '2' '4' '2' '4' '4' '4' '2' '2' '4'\n",
      " '2' '2' '4' '2' '2' '2' '2' '2' '4' '4' '4' '2' '4' '2' '2' '2' '4' '4'\n",
      " '2' '4' '2' '4' '2' '2' '4' '2' '2' '2' '2' '2' '2' '2' '4' '2' '4' '2'\n",
      " '4' '4' '2' '4' '4' '2']\n",
      "Accuracy is  96.49122807017544 % for K-Value: 10\n",
      "0.9649122807017544\n",
      "['4' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '4' '2' '4' '2' '4'\n",
      " '4' '4' '4' '4' '2' '2' '4' '2' '2' '2' '2' '4' '2' '4' '2' '4' '2' '4'\n",
      " '2' '4' '2' '4' '4' '2' '4' '2' '2' '4' '2' '2' '2' '4' '4' '2' '4' '2'\n",
      " '2' '2' '2' '2' '2' '4' '4' '4' '2' '2' '4' '2' '4' '4' '4' '2' '2' '4'\n",
      " '2' '2' '4' '2' '2' '2' '2' '2' '4' '4' '4' '2' '4' '2' '2' '2' '4' '4'\n",
      " '2' '4' '2' '4' '2' '2' '4' '2' '2' '2' '2' '2' '2' '2' '4' '2' '4' '2'\n",
      " '4' '4' '2' '4' '4' '2']\n",
      "Accuracy is  96.49122807017544 % for K-Value: 11\n",
      "0.9649122807017544\n",
      "['4' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '4' '2' '4' '2' '4'\n",
      " '4' '4' '4' '4' '2' '2' '4' '2' '2' '2' '2' '4' '2' '4' '2' '4' '2' '4'\n",
      " '2' '4' '2' '4' '4' '2' '4' '2' '2' '4' '2' '2' '2' '4' '4' '2' '4' '2'\n",
      " '2' '2' '2' '2' '2' '4' '4' '4' '2' '2' '4' '2' '4' '4' '4' '2' '2' '4'\n",
      " '2' '2' '4' '2' '2' '2' '2' '2' '4' '4' '4' '2' '4' '2' '2' '2' '4' '4'\n",
      " '2' '4' '2' '4' '2' '2' '4' '2' '2' '2' '2' '2' '2' '2' '4' '2' '4' '2'\n",
      " '4' '4' '2' '4' '4' '2']\n",
      "Accuracy is  96.49122807017544 % for K-Value: 12\n",
      "0.9649122807017544\n",
      "['4' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '4' '2' '4' '2' '4'\n",
      " '4' '4' '4' '4' '2' '2' '4' '2' '2' '2' '2' '4' '2' '4' '2' '4' '2' '4'\n",
      " '2' '4' '2' '4' '4' '2' '4' '2' '2' '4' '2' '2' '2' '4' '4' '2' '4' '2'\n",
      " '2' '2' '2' '2' '2' '4' '4' '4' '2' '2' '4' '2' '4' '4' '4' '2' '2' '4'\n",
      " '2' '2' '4' '2' '2' '2' '2' '2' '4' '4' '4' '2' '4' '2' '2' '2' '4' '4'\n",
      " '2' '4' '2' '4' '2' '2' '4' '2' '2' '2' '2' '2' '2' '2' '4' '2' '4' '2'\n",
      " '4' '4' '2' '4' '4' '2']\n",
      "Accuracy is  96.49122807017544 % for K-Value: 13\n",
      "0.9649122807017544\n",
      "['4' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '4' '2' '4' '2' '4'\n",
      " '4' '4' '4' '4' '2' '2' '4' '2' '2' '2' '2' '4' '2' '4' '2' '4' '2' '4'\n",
      " '2' '4' '2' '4' '4' '2' '4' '2' '2' '4' '2' '2' '2' '4' '4' '2' '4' '2'\n",
      " '2' '2' '2' '2' '2' '4' '4' '4' '2' '2' '4' '2' '4' '4' '4' '2' '2' '4'\n",
      " '2' '2' '4' '2' '2' '2' '2' '2' '4' '4' '4' '2' '4' '2' '2' '2' '4' '4'\n",
      " '2' '4' '2' '4' '2' '2' '4' '2' '2' '2' '2' '2' '2' '2' '4' '2' '4' '2'\n",
      " '4' '4' '2' '4' '4' '2']\n",
      "Accuracy is  96.49122807017544 % for K-Value: 14\n",
      "0.9649122807017544\n",
      "['4' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '4' '2' '4' '2' '4'\n",
      " '4' '4' '4' '4' '2' '2' '4' '2' '2' '2' '2' '4' '2' '4' '2' '4' '2' '4'\n",
      " '2' '4' '2' '4' '4' '2' '4' '2' '2' '4' '2' '2' '2' '4' '4' '2' '4' '2'\n",
      " '2' '2' '2' '2' '2' '4' '4' '4' '2' '2' '4' '2' '4' '4' '4' '2' '2' '4'\n",
      " '2' '2' '4' '2' '2' '2' '2' '2' '4' '4' '4' '2' '4' '2' '2' '2' '4' '4'\n",
      " '2' '4' '2' '4' '2' '2' '4' '2' '2' '2' '2' '2' '2' '2' '4' '2' '4' '2'\n",
      " '4' '4' '2' '4' '4' '2']\n",
      "Accuracy is  96.49122807017544 % for K-Value: 15\n",
      "0.9649122807017544\n",
      "Accuracy score 0.964912\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       0.96      0.99      0.97        67\n",
      "           4       0.98      0.94      0.96        47\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.97      0.96      0.96       114\n",
      "weighted avg       0.97      0.96      0.96       114\n",
      "\n",
      "[[66  1]\n",
      " [ 3 44]]\n",
      "Neighbors: 1, Accuracy: 0.964912\n",
      "Neighbors: 3, Accuracy: 0.964912\n",
      "Neighbors: 5, Accuracy: 0.964912\n",
      "Neighbors: 7, Accuracy: 0.964912\n",
      "Neighbors: 9, Accuracy: 0.964912\n",
      "Neighbors: 11, Accuracy: 0.964912\n",
      "Neighbors: 13, Accuracy: 0.964912\n",
      "Neighbors: 15, Accuracy: 0.964912\n",
      "Neighbors: 17, Accuracy: 0.964912\n",
      "Neighbors: 19, Accuracy: 0.964912\n",
      "Neighbors: 21, Accuracy: 0.964912\n",
      "Neighbors: 23, Accuracy: 0.964912\n",
      "Neighbors: 25, Accuracy: 0.964912\n",
      "Neighbors: 27, Accuracy: 0.964912\n",
      "Neighbors: 29, Accuracy: 0.964912\n",
      "Neighbors: 31, Accuracy: 0.964912\n",
      "Neighbors: 33, Accuracy: 0.964912\n",
      "Neighbors: 35, Accuracy: 0.964912\n",
      "Neighbors: 37, Accuracy: 0.964912\n",
      "Neighbors: 39, Accuracy: 0.964912\n",
      "Neighbors: 41, Accuracy: 0.964912\n",
      "Neighbors: 43, Accuracy: 0.964912\n",
      "Neighbors: 45, Accuracy: 0.964912\n",
      "Neighbors: 47, Accuracy: 0.964912\n",
      "Neighbors: 49, Accuracy: 0.964912\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#import mglearn\n",
    "import time\n",
    "\n",
    "\n",
    "#Load the file\n",
    "data = pd.read_csv('U:/datascience/knn/Dataset-c.csv',\n",
    "                   index_col=False)\n",
    "print(data.head(5))\n",
    "print(data.shape)\n",
    "print(data.describe())\n",
    "\n",
    "#Replace 'M' and 'B' with 4 and 2\n",
    "data['diagnosis'] =  data['diagnosis'].apply(lambda x: '2' if x == 'B' else '4')\n",
    "data = data.set_index('id')\n",
    "#del data['Unnamed: 32']\n",
    "#print(data)\n",
    "\n",
    "#print(data.groupby('diagnosis').size())\n",
    "\n",
    "#split the data into predictor variables and target variable, following by breaking them into train and test sets.\n",
    "# We will use 20% of the data as test set.\n",
    "y = data['diagnosis'].values\n",
    "X = data.drop('diagnosis', axis=1).values\n",
    "\n",
    "#SPlit the data set\n",
    "X_train, X_test, y_train, y_test = train_test_split (X, y, test_size = 0.20,random_state=0)\n",
    "\n",
    "#Baseline algorithm checking\n",
    "#From the dataset, we will analysis and build a model to predict if a given set of symptoms lead to breast cancer.\n",
    "#Create empty list\n",
    "models_list = []\n",
    "#Append the algorithm name and instance\n",
    "models_list.append(('KNN', KNeighborsClassifier()))\n",
    "models_list.append(('Logistic', LogisticRegression()))\n",
    "#print(models_list)\n",
    "\n",
    "#Divide the dataset into 10 subsets\n",
    "num_folds = 10\n",
    "#Storing the result\n",
    "results = []\n",
    "#Storing the names\n",
    "names = []\n",
    "\n",
    "for name, model in models_list:\n",
    "    kfold = KFold(n_splits=num_folds, random_state=0)\n",
    "    cv_results = cross_val_score(model, X_train, y_train,\n",
    "                                 cv=kfold, scoring='accuracy')\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    print(name, cv_results.mean(), cv_results.std())\n",
    "for K in range(15):\n",
    "    Kvalue = K + 1\n",
    "    knclassifier = KNeighborsClassifier(n_neighbors=Kvalue, \n",
    "                                        weights='uniform', algorithm='auto')\n",
    "    knclassifier.fit(X_train, y_train)\n",
    "    y_pred = knclassifier.predict(X_test)\n",
    "    print(y_pred)\n",
    "    print(\"Accuracy is \", accuracy_score(y_test,y_pred)* 100,\n",
    "          \"% for K-Value:\",Kvalue)\n",
    "    accuracy = knclassifier.score(X_test, y_test)\n",
    "    print(accuracy)\n",
    "\n",
    "#mglearn.plots.plot_knn_classification(n_neighbors=1)\n",
    "#plt.show()\n",
    "print(\"Accuracy score %f\" % accuracy_score(y_test, y_pred))\n",
    "#Classification Report\n",
    "print(classification_report(y_test, y_pred))\n",
    "#Confusion Matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "results1 = []\n",
    "#print(np.sum(y_pred == y_test) / float(len(y_test)))\n",
    "for n in range(1, 51, 2):\n",
    "    accuracy = np.sum(y_pred == y_test) / float(len(y_test))\n",
    "    print(\"Neighbors: %d, Accuracy: %3f\" % (n, accuracy))\n",
    "    results1.append([n, accuracy])\n",
    "results1 = pd.DataFrame(results1, columns=[\"n\", \"accuracy\"])\n",
    "plt.plot(results1.n, results1.accuracy)\n",
    "plt.title(\"Accuracy with Increasing K\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
